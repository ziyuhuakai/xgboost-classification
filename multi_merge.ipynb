{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.utils import shuff\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution1D, MaxPooling1D, Flatten, Dropout, concatenate\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "# import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.loadtxt('G:/newligo20181220/杏仁分类/workdata/X_xingren.txt')\n",
    "y = np.loadtxt('G:/newligo20181220/杏仁分类/workdata/y_xingren.txt')\n",
    "y = y - np.ones(np.size(y))\n",
    "\n",
    "\n",
    "# X =pd.DataFrame(X,columns=['featr%d'%i for i in range(X.shape[1])])\n",
    "# X.head()\n",
    "# y =pd.DataFrame(y)\n",
    "seed=7\n",
    "test_size=0.33\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=seed)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# X_new = SelectKBest(f_classif, k=1000).fit_transform(X_train, y_train)\n",
    "m,n=X_train.shape\n",
    "x = np.zeros((m, n, 1))\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        x[i, j, 0] = X_train[i, j]\n",
    "X_train = x\n",
    "\n",
    "m,n=X_test.shape\n",
    "x = np.zeros((m, n, 1))\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        x[i, j, 0] = X_test[i, j]\n",
    "X_test= x\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input1_= Input(shape=(1704, 1), name='input1')\n",
    "input2_ = Input(shape=(1704, 1), name='input2')\n",
    "\n",
    "result = Sequential()\n",
    "\n",
    "add1 = Convolution1D(16, 16, activation='relu', batch_input_shape=(71, 1704, 1))(input1_)\n",
    "add2 = MaxPooling1D(pool_size=2)(add1)\n",
    "add3 = Dropout(0.5)(add2)\n",
    "add4 = Convolution1D(32, 8, activation='relu')(add3)\n",
    "add5 = MaxPooling1D(pool_size=2)(add4)\n",
    "add6 = Dropout(0.5)(add5)\n",
    "add7 = Flatten()(add6)\n",
    "add8 = Dense(512, activation='relu')(add7)\n",
    "add9 = Dropout(0.5)(add8)\n",
    "print(add9)\n",
    "\n",
    "\n",
    "l1=LSTM(512, return_sequences=True)(input2_)\n",
    "l2 = Dropout(0.5)(l1)\n",
    "l3=LSTM(512, return_sequences=True)(l2)\n",
    "l4 = Dropout(0.5)(l3)\n",
    "l5=LSTM(512)(l4)\n",
    "l6 = Dropout(0.5)(l5)\n",
    "print(l6)\n",
    "\n",
    "\n",
    "merged = concatenate([add9, l6])\n",
    "\n",
    "# result.add(merged)\n",
    "output = Dense(7, activation='softmax')(merged)\n",
    "\n",
    "model = Model(inputs=[input1_, input2_], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# 神经网络建立完毕\n",
    "\n",
    "y_train = to_categorical(y_train, 7)\n",
    "y_test = to_categorical(y_test, 7)\n",
    "\n",
    "model.fit([X_train,X_train], y_train, batch_size=71, epochs=200)\n",
    "\n",
    "f.mkdir('model')\n",
    "path = 'model' + '/' + 'model_多分类_multi.h5'\n",
    "model.save(path)\n",
    "print('训练完成，训练后的模型保存在：' + path + '文件中')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
